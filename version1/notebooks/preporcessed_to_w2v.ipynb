{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def removeUnicode(text):\n",
    "\t#Removes unicode strings like \"\\u002c\" and \"x96\"\n",
    "\ttext = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', text)       \n",
    "\ttext = re.sub(r'[^\\x00-\\x7f]',r'',text)\n",
    "\treturn text\n",
    "\n",
    "def replaceURL(text):\n",
    "\t#Replaces url address with \"url\" \n",
    "\ttext = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','<url>',text)\n",
    "\ttext = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "\treturn text\n",
    "\n",
    "def replaceAtUser(text):\n",
    "\t#Replaces \"@user\" with \"atUser\"\n",
    "\ttext = re.sub('@[^\\s]+','atUser',text)\n",
    "\treturn text\n",
    "\n",
    "def removeHashtag(text):\n",
    "\t#Removes hastag in front of a word\n",
    "\ttext = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "\treturn text\n",
    "\n",
    "def removeNumbers(text):\n",
    "\t#Removes integers\n",
    "\ttext = ''.join([i for i in text if not i.isdigit()])         \n",
    "\treturn text\n",
    "\n",
    "def replaceMulExcl(text):\n",
    "\t#Replaces repetitions of exlamation marks\n",
    "\ttext = re.sub(r\"(\\!)\\1+\", '!', text)\n",
    "\treturn text\n",
    "\n",
    "def replaceMulQues(text):\n",
    "\t#Replaces repetitions of question marks\n",
    "\ttext = re.sub(r\"(\\?)\\1+\", '?', text)\n",
    "\treturn text\n",
    "\n",
    "def replaceMulStop(text):\n",
    "\t#Replaces repetitions of stop marks\n",
    "\ttext = re.sub(r\"(\\.)\\1+\", '.', text)\n",
    "\treturn text\n",
    "\n",
    "def countMulExcl(text):\n",
    "\t#count repetitions of exlamation marks\n",
    "\treturn len(re.findall(r\"(\\!)\\1+\", text))\n",
    "\n",
    "def countMulQues(text):\n",
    "\t#Count repetitions of question marks\n",
    "\treturn len(re.findall(r\"(\\?)\\1+\", text))\n",
    "\n",
    "def countMulStop(text):\n",
    "\t#Count repetitions of stop marks\n",
    "\treturn len(re.findall(r\"(\\.)\\1+\", text))\n",
    "\n",
    "def countElongated(text):\n",
    "\t#count of how many words are elongated\n",
    "\tregex = re.compile(r\"(.)\\1{2}\")\n",
    "\treturn len([word for word in text.split() if regex.search(word)])\n",
    "\n",
    "def countAllCaps(text):\n",
    "\t#count of how many words are all caps\n",
    "\treturn len(re.findall(\"[A-Z0-9]{3,}\", text))\n",
    "\n",
    "#Creates a dictionary with slangs and their equivalents and replaces them\n",
    "with open('slang.txt') as file:\n",
    "\tslang_map = dict(map(str.strip, line.partition('\\t')[::2])\n",
    "\tfor line in file if line.strip())\n",
    "\n",
    "slang_words = sorted(slang_map, key=len, reverse=True)\n",
    "regex = re.compile(r\"\\b({})\\b\".format(\"|\".join(map(re.escape, slang_words))))\n",
    "replaceSlang = partial(regex.sub, lambda m: slang_map[m.group(1)])\n",
    "\n",
    "#punctuation list for replacing\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '|', ';', \"'\", '$', '&', '/', '[', ']', '%', '=', '*', '+', '\\\\', '•',  '~', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def removePuncts(x):\n",
    "\tx = str(x)\n",
    "\tfor punct in puncts:\n",
    "\t\tif punct in x:\n",
    "\t\t\tx = x.replace(punct, f' ')\n",
    "\treturn x\n",
    "\n",
    "\n",
    "\n",
    "def countSlang(text):\n",
    "\t# counts how many slang words and a list of found slangs\n",
    "\tslangCounter = 0\n",
    "\tslangsFound = []\n",
    "\ttokens = nltk.word_tokenize(text)\n",
    "\tfor word in tokens:\n",
    "\t\tif word in slang_words:\n",
    "\t\t\tslangsFound.append(word)\n",
    "\t\t\tslangCounter += 1\n",
    "\treturn slangCounter, slangsFound\n",
    "\n",
    "#Replaces contractions from a string to their equivalents\n",
    "contraction_patterns = [ (r'I\\'m', 'I am'),(r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "\t\t\t\t\t\t (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not') ]\n",
    "def replaceContraction(text):\n",
    "\tpatterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "\tfor (pattern, repl) in patterns:\n",
    "\t\t(text, count) = re.subn(pattern, repl, text)\n",
    "\treturn text\n",
    "\n",
    "def replaceElongated(word):\n",
    "\t#Replaces an elongated word with its basic form\n",
    "\n",
    "\trepeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "\trepl = r'\\1\\2\\3'\n",
    "\tif wordnet.synsets(word):\n",
    "\t\treturn word\n",
    "\trepl_word = repeat_regexp.sub(repl, word)\n",
    "\tif repl_word != word:      \n",
    "\t\treturn replaceElongated(repl_word)\n",
    "\telse:       \n",
    "\t\treturn repl_word\n",
    "\n",
    "def removeEmoticons(text):\n",
    "\t#Removes emoticons from text \n",
    "\ttext = re.sub(':\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-*|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\*\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:', '', text)\n",
    "\treturn text\n",
    "\n",
    "def countEmoticons(text):\n",
    "\t#Input: a text, Output: how many emoticons\n",
    "\treturn len(re.findall(':\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-*|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\*\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:', text))\n",
    "\n",
    "\n",
    "### Spell Correction begin ###\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('spell_correction.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "\t#P robability of `word`.\n",
    "\treturn WORDS[word] / N\n",
    "\n",
    "def spellCorrection(word): \n",
    "\t#Most probable spelling correction for word.\n",
    "\treturn max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "\t#Generate possible spelling corrections for word.\n",
    "\treturn (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "\t#The subset of `words` that appear in the dictionary of WORDS.\n",
    "\treturn set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "\t#All edits that are one edit away from `word`.\n",
    "\tletters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\tsplits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "\tdeletes    = [L + R[1:]               for L, R in splits if R]\n",
    "\ttransposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "\treplaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "\tinserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "\treturn set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "\t#All edits that are two edits away from `word`.\n",
    "\treturn (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "### Spell Correction End ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from time import time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "def k_prep(inputText = 'null'):\n",
    "\t'''\n",
    "\tc = input(\"\\n1.Enter or 2.default or 3.df ? :\")\n",
    "\n",
    "\tif c == \"2\":\n",
    "\t\ttext = \"AFRICA,#AFRICANBAZE: asap goaaaaal @Breaking !!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze..... 12000 in America. http://t.co/2nndBGwyEi,1\"\n",
    "\t\t#print(text)\n",
    "\t\n",
    "\telif c == \"3\" :\n",
    "\t\ttext = inputText\n",
    "\n",
    "\telse:\n",
    "\t\ttext = input(\"\\nEnter the tweet: \")\n",
    "\t'''\n",
    "\n",
    "\ttext = inputText\n",
    "\t#print(\"\\nReplacing url from tweet\\n\")\n",
    "\ttext = replaceURL(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nReplacing atuser from tweet\\n\")\n",
    "\ttext = replaceAtUser(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nremoving hashtag in tweet\\n\")\n",
    "\ttext = removeHashtag(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nreplace at user in tweet\\n\")\n",
    "\ttext = replaceAtUser(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t'''\n",
    "\t#print(\"\\nremoving stopwords\\n\")\n",
    "\t#nltk.download('stopwords')\n",
    "\tfrom nltk.corpus import stopwords\n",
    "\tstop = set(stopwords.words('english'))\n",
    "\n",
    "\td=[]\n",
    "\td.append([x for x in text.split() if x not in stop])\n",
    "\td = d[0]\n",
    "\ttext = ' '.join(d)\n",
    "\t#print(text)\n",
    "\t'''\n",
    "\n",
    "\t#print(\"\\nremove numbers from tweet\\n\")\n",
    "\ttext = removeNumbers(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nremove emoticons from tweet\\n\")\n",
    "\ttext = removeEmoticons(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#couting multple punctuations\n",
    "\t#print(\"\\ncounting multiple punctuations\\n\")\n",
    "\tMultiExclMarks = 0\n",
    "\tMultiQuesMarks = 0\n",
    "\tMultiStopMarks = 0\n",
    "\n",
    "\tMultiExclMarks += countMulExcl(text)\n",
    "\tMultiQuesMarks += countMulQues(text)\n",
    "\tMultiStopMarks += countMulStop(text)\n",
    "\n",
    "\t#print(MultiExclMarks,MultiQuesMarks,MultiStopMarks)\n",
    "\n",
    "\t#print(\"\\nremove multiexclamations from tweet\\n\")\n",
    "\ttext = replaceMulExcl(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nremove multiquestionmarks from tweet\\n\")\n",
    "\ttext = replaceMulQues(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nremove multistopmarks from tweet\\n\")\n",
    "\ttext = replaceMulStop(text)\n",
    "\t#print(text)\n",
    "\n",
    "\n",
    "\t#print(\"\\nshortening elongated words\\n\")\n",
    "\ttotalElongated = 0\n",
    "\ttotalElongated += countElongated(text)\n",
    "\t#print(totalElongated)\n",
    "\n",
    "\tregex1 = re.compile(r\"(.)\\1{2}\")\n",
    "\tl=[]\n",
    "\tfor word in text.split():\n",
    "\t\tif(regex1.search(word)):\n",
    "\t\t\tnew_word = replaceElongated(word)\n",
    "\t\t\t##print(new_word)\n",
    "\t\t\tl.append(new_word)\n",
    "\t\telse:\n",
    "\t\t\tl.append(word)\n",
    "\ttext = ' '.join(l)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nRemoving punctuations except ?!\\n\")\n",
    "\ttext = removePuncts(text)\n",
    "\t#print(text)\n",
    "\t\n",
    "\t#print(\"\\nexpanding slangs in tweet\\n\")\n",
    "\ttext = replaceSlang(text)\n",
    "\t#print(text)\n",
    "\n",
    "\t#print(\"\\nreplace contractions in tweet\\n\")\n",
    "\ttext = replaceContraction(text)\n",
    "\t#print(text)\n",
    "\t\n",
    "\t#print(\\nTokenizing the text\\n\")\n",
    "\ttext = word_tokenize(text)\n",
    "\t\n",
    "\t#print(\"\\nLemmatizing the text\\n\")\n",
    "\tlemma = WordNetLemmatizer()\n",
    "\t\n",
    "\tlist1 = []\n",
    "\tfor txt in text:\n",
    "\t\tlist1.append(lemma.lemmatize(txt))\n",
    "\t\t\n",
    "\treturn list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [Our, Deeds, are, the, Reason, of, this, earth...\n",
      "1           [Forest, fire, near, La, Ronge, Sask, Canada]\n",
      "2       [All, resident, asked, to, shelter, in, place,...\n",
      "3       [people, receive, wildfire, evacuation, order,...\n",
      "4       [Just, got, sent, this, photo, from, Ruby, Ala...\n",
      "                              ...                        \n",
      "7608    [Two, giant, crane, holding, a, bridge, collap...\n",
      "7609    [atUser, atUser, The, out, of, control, wild, ...\n",
      "7610    [M, UTC, ?, km, S, of, Volcano, Hawaii, <, url...\n",
      "7611    [Police, investigating, after, an, e, bike, co...\n",
      "7612    [The, Latest, More, Homes, Razed, by, Northern...\n",
      "Name: text, Length: 7613, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "df = pd.read_csv(\"../dataset/train.csv\")\n",
    "df['text'] = df['text'].apply(k_prep)\n",
    "print(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the w2c model\n",
    "# use this or below one\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../../../temp/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.4313e-01,  1.1597e-02,  3.8135e-01, -5.8350e-01,  1.4441e-01,\n",
       "        5.6247e-01,  5.2358e-01,  2.0859e-01,  3.6430e-01,  1.6414e-01,\n",
       "        2.1116e-01, -8.2224e-02, -3.4245e-01, -4.9223e-01, -4.7266e-01,\n",
       "       -4.2001e-01, -2.2613e-01, -5.3931e-01, -7.0124e-02, -2.2233e-01,\n",
       "        9.9192e-02, -6.3968e-01,  1.3386e-03, -1.5225e-01,  3.8554e-02,\n",
       "        5.5047e-01,  1.2805e-01, -1.2323e-01,  3.9681e-01, -2.5109e-01,\n",
       "       -4.2492e-01,  2.4405e-01, -2.8350e-01,  5.3093e-02,  1.5388e-01,\n",
       "        7.1608e-01,  4.7376e-01, -4.0382e-02,  2.3105e-01,  2.2754e-01,\n",
       "        3.2284e-01,  2.8145e-01,  2.5730e-01, -2.0180e-01,  2.6585e-01,\n",
       "        3.7243e-01,  1.4099e-02, -1.3031e-01,  1.3321e-01,  5.6750e-01,\n",
       "       -3.4187e-01, -1.6419e-01, -1.3811e-01,  3.5900e-01, -2.5174e-01,\n",
       "       -7.1623e-02, -4.2692e-01, -2.7603e-02,  3.3421e-01,  5.4517e-01,\n",
       "        2.5155e-01,  6.7958e-01,  1.4540e-02, -1.2633e-01, -1.2560e-01,\n",
       "       -4.1516e-01, -5.4850e-01,  8.1463e-02, -1.8129e-01,  6.3413e-01,\n",
       "       -2.4634e-02,  2.3230e-01,  2.0077e-01,  4.3041e-01, -2.4465e-01,\n",
       "       -2.5664e-01,  1.7678e-01, -2.0238e-01,  6.4595e-01, -1.9773e-01,\n",
       "        1.5065e-01, -1.0206e-01, -5.3518e-02, -1.1535e-01,  3.5994e-01,\n",
       "        1.9732e-01, -8.5075e-01, -1.8543e-01,  8.0268e-02, -4.8602e-01,\n",
       "       -6.2662e-02, -1.7122e-01, -3.9803e-02,  1.4594e-01, -4.4899e-01,\n",
       "        2.4900e-01, -3.7785e-01,  2.1567e-01, -1.4614e-01, -3.6532e-01,\n",
       "        9.2223e-02,  8.2460e-02, -1.9867e-01,  1.4597e-01,  3.1013e-02,\n",
       "       -1.4401e-01,  1.8919e-01, -9.5515e-02,  5.3947e-01, -2.1068e-01,\n",
       "       -3.9397e-01,  6.2997e-03, -2.8242e-01, -2.1170e-01,  2.9400e-01,\n",
       "       -2.3237e-02,  8.2254e-04,  2.9611e-01,  2.4428e-01,  2.6709e-01,\n",
       "       -4.5705e-03,  2.8931e-01, -3.7802e-01,  6.2517e-01,  1.1831e-01,\n",
       "        1.8778e-01,  1.2689e-01, -5.1906e-02, -2.7035e-02,  9.6538e-02,\n",
       "       -3.1837e-01, -7.2485e-01,  3.1659e-01, -1.5976e-01,  6.9624e-03,\n",
       "       -1.4241e-01,  3.7018e-01, -3.3372e-02, -2.0297e-01, -7.6789e-02,\n",
       "       -2.1325e-02, -4.1149e-03, -2.5860e-01, -3.2062e-01,  4.1450e-02,\n",
       "        1.8655e-01,  7.7355e-01,  5.6009e-01, -1.9159e-01, -2.9748e-01,\n",
       "        2.4735e-01,  3.4051e-01, -5.7618e+00,  1.6381e-01,  5.2690e-01,\n",
       "        6.3680e-01, -6.1341e-01,  3.8122e-01, -2.3048e-01,  2.8040e-01,\n",
       "        5.1146e-02, -3.0164e-01,  2.9694e-01,  6.4160e-01, -3.2999e-01,\n",
       "        1.6247e-01,  1.1166e-01, -1.7053e-02, -1.0584e-01,  1.9130e-01,\n",
       "       -4.1105e-01, -2.5708e-01,  1.5332e-01, -2.0657e-01, -1.1029e-01,\n",
       "       -1.7693e-01, -2.0621e-01, -6.1523e-01,  1.7892e-01, -1.0824e-01,\n",
       "       -4.9030e-02,  3.4122e-01, -2.4905e-01,  3.8001e-01,  3.4689e-02,\n",
       "       -2.1912e-01,  4.4193e-01, -7.5872e-01,  1.1349e-01,  8.5856e-02,\n",
       "        2.0097e-01,  1.5379e-01,  1.1783e-01, -8.9151e-02, -1.5801e-01,\n",
       "       -1.7336e-01,  5.3917e-01, -8.7230e-02, -2.3225e-01,  3.5895e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using glove instead fo w2c\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#glove_file = datapath('../../../temp/glove/glove.twitter.27B.25d.txt')\n",
    "#tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "#glove2word2vec(glove_file, tmp_file)\n",
    "glove2word2vec(glove_input_file=\"../../../temp/glove/glove.twitter.27B.200d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")\n",
    "model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\")\n",
    "model['go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def document_vector(model,doc):\n",
    "\t#filename = 'glove.twitter.27B.25d.txt.word2vec'\n",
    "\t#model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "\t# remove out-of-vocabulary words\n",
    "\tdoc = [word for word in doc if word in model.vocab]\n",
    "\treturn np.mean(model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.021657309, 0.07887014, 0.07608032, 0.08251953, -0.11894735, 0.011985779, -0.0075937905, -0.057469685, 0.057718914, 0.16297404, -0.07683054, -0.005299886, 0.0073140464, 0.08076986, -0.07671102, 0.036931355, 0.098749794, 0.042013805, -0.027061462, -0.029106775, 0.05234782, 0.07655843, 0.16868591, -0.061735153, 0.04561615, 0.054016113, -0.0368042, -0.029675802, -0.0004310608, -0.10961914, -0.02190272, -0.017323812, -0.10821533, -0.09498882, -7.3750816e-05, 0.047477085, -0.046407063, -0.003672282, 0.005845388, 0.09196981, 0.13048808, -0.036346436, 0.116999306, 0.10116577, 0.07077026, -0.022185007, -0.0032170613, 0.043485004, -0.07024256, 0.07159487, -0.041610718, 0.109817505, -0.015406291, 0.029388428, 0.022155762, 0.06945547, -0.09511312, -0.01908048, -0.034551937, -0.055216473, -0.03354009, 0.0558726, -0.10597229, -0.07423655, -0.016693115, -0.068384804, -0.031606037, 0.07804362, -0.01600647, -0.019417444, -0.022867838, -0.025756836, -0.010467529, -0.027395884, -0.083039604, -0.04373169, 0.092043556, -0.012379964, 0.10903422, 0.032877605, -0.09737142, -0.11596934, 0.023460388, -0.04257202, -0.057437897, -0.076405846, -0.100982666, 0.08616638, 0.055608112, 0.014574687, -0.003829956, 0.043128967, 0.04032898, -0.03872172, -0.0320638, 0.019104004, 0.09574127, 0.07051595, 0.095149994, -0.041484833, -0.09120067, -0.044466656, 0.042104084, 0.031626385, 0.007306417, 0.0018590292, -0.11859131, -0.010187785, 0.024627686, -0.008412679, -0.07228851, -0.07781728, 0.04597473, 0.0029729207, 0.1373698, 0.04905192, 0.0120442705, -0.012720744, 0.070627846, 0.045855206, -0.0005289714, 0.07627233, -0.07369995, -0.0020548503, -0.01961263, 0.008831342, -0.09399414, -0.042989094, 0.061960857, 0.0001004537, -0.100997925, -0.11393992, -0.053108215, -0.07274882, 0.036916096, -0.10673523, 0.0032653809, -0.044830322, 0.077067055, 0.13427734, 0.08657074, -0.036046345, 0.08899975, -0.08189392, -0.052083332, -0.034639996, 0.038584393, -0.05159505, 0.018038431, -0.05211385, 0.012886047, -0.045094807, 0.015858969, -0.054656982, 0.047383625, -0.020924887, 0.07584635, -0.023456573, 0.0008277893, -0.062202454, -0.016001383, 0.016438803, 0.060496014, 0.06819407, 0.025797525, -0.14269765, 0.1075236, -0.009117126, -0.006174723, 0.0410258, -0.10254415, -0.06745911, -0.003540039, -0.16197713, -0.015733084, 0.08154297, 0.018798828, -0.09237925, 0.060791016, -0.10192871, -0.16601562, 0.006617228, -0.037699383, -0.017117819, 0.008853912, 0.04401652, -0.10157267, -0.055624645, 0.118509926, 0.081973396, -0.03535843, 0.07521566, -0.036705017, -0.01078542, -0.105189, 0.11406454, -0.010927836, 0.05513255, -0.01008606, -0.09195963, -0.07309469, -0.038533527, -0.041559856, -0.012374878, -0.076203026, 0.013865153, -0.066469826, 0.026468912, 0.030095419, 0.07646179, -0.01361084, 0.014336904, 0.016726175, -0.06582896, -0.16015625, 0.017932892, 0.06490072, 0.02166748, -0.076049805, -0.04266866, -0.015604655, 0.008392334, -0.00039927164, -0.07171345, 0.07410685, -0.06452433, 0.021929422, 0.085642494, 0.009668986, -0.02516683, 0.093800865, 0.03898112, 0.0343221, 0.03498332, -0.046848934, 0.05585734, 0.009318034, -0.006627401, -0.008728027, 0.07144928, 0.01214091, 0.03371175, -0.039513905, -0.107167564, -0.034688313, 0.008593242, 0.012972514, 0.13326518, -0.1327006, -0.041488647, 0.026367188, 0.06780752, 0.021402994, 0.062815346, 0.04714966, -0.14174397, 0.049641926, -0.016000748, 0.037038166, -0.051376343, -0.04348755, -0.02082316, 0.0061442056, -0.024556478, -0.048243206, 0.13343811, -0.092811584, -0.017690023, -0.05765788, -0.09702873, -0.03949992, 0.12820435, 0.11103312, 0.122934975, 0.018859863, 0.042419434, -0.011362712, -0.071126305, -0.025024414, 0.05472819, -0.031194052, 0.027675629, 0.04755656, 0.043192547, 0.08202616, -0.010131836, -0.05262248, -0.03028361, 0.022420248, 0.090901695, -0.05323283, 0.02986908, -0.0976766, -0.06477865, -0.01905314, -0.084009804, -0.077952065, -0.07090505, 0.0010579427, 0.08579508], [0.077427454, 0.018101284, 0.11669922, 0.069196425, 0.036717005, -0.04134696, -0.107395716, -0.026310513, -0.022112165, -0.023856027, -0.019074576, -0.034441266, -0.03362165, -0.16782925, -0.032069616, -0.12374442, 0.03100586, 0.12974331, -0.037231445, 0.031450544, -0.0004185268, 0.013340541, -0.098772325, 0.06493705, 0.10091727, 0.024257114, -0.15440151, 0.051810127, 0.1565639, 0.01032366, 0.076590404, -0.11478097, -0.10268729, -0.17294857, 0.016601562, -0.1546936, -0.12360491, 0.119559154, 0.06839425, -0.18204607, -0.17776926, -0.06397792, -0.0062430245, -0.14517649, -0.0869533, -0.01410784, -0.19749233, -0.041451592, 0.004045759, 0.10710798, -0.006417411, -0.0020577568, 0.04875837, -0.031267438, -0.1727551, 0.0041155135, -0.07931083, -0.050183978, -0.05695452, -0.09047154, -0.0650504, 0.14406912, 0.058401924, 0.016784668, -0.11379569, -0.05430385, 0.061192103, -0.08687919, -0.06966727, 0.09284319, 0.049508233, -0.008113316, 0.054997034, -0.053902764, 0.0007672991, 0.024217878, 0.0042027063, -0.048461914, 0.07751465, 0.06935338, -0.017804828, -0.0069231307, 0.055742536, -0.016584124, -0.046822686, -0.06368583, -0.13715471, 0.19398716, -0.055873327, -0.020071847, -0.065290175, -0.058663506, -0.016017368, 0.090419225, -0.12166487, 0.031842913, 0.1585519, -0.046718054, 0.016671317, -0.14142717, -0.063197546, -0.14276995, -0.014990671, -0.05810547, 0.06975447, -0.16594587, 0.042938232, -0.04823521, -0.08399309, 0.08021764, -0.10288783, 0.016087124, 0.09080287, -0.0055454797, 0.053353447, -0.04108538, 0.012486049, -0.03138951, -0.114449635, 0.058523994, 0.011544364, -0.044032507, -0.09981864, 0.025111606, 0.0991854, -0.11758859, -0.12433733, -0.13004848, -0.06431361, 0.18216379, -0.10623659, -0.03416225, -0.13630785, -0.11943708, 0.0010555813, 0.03777204, -0.09280831, -0.025129046, -0.018371582, 0.18973215, 0.22997175, -0.104755946, 0.134055, -0.07634626, 0.11455209, 0.03252956, -0.012625558, 0.00982666, -0.0642613, -0.058122907, 0.02797154, -0.029933384, 0.075038366, 0.024257114, -0.014020647, -0.047345843, 0.15980747, 0.103271484, 0.0076032365, -0.007638114, 0.08542306, 0.056884766, -0.0029820034, 0.084577285, 0.1273019, -0.017926898, 0.021641323, 0.06847273, 0.059404645, 0.06497628, -0.11596244, -0.13827951, 0.013828822, -0.1980351, -0.05415998, -0.04288592, 0.047348294, -0.01586914, -0.11654227, -0.039866857, -0.1344866, -0.07066127, 0.118722096, -0.15157644, -0.10253906, -0.13424246, -0.005458287, 0.09465681, -0.0033830914, 0.15356445, -0.06509835, -0.05643136, -0.050192695, 0.0056762695, -0.07976423, 0.017294748, -0.0047956193, 0.030147007, 0.0710798, 0.096296035, 0.1488909, -0.030796597, 0.113130845, -0.23842075, -0.01738957, 0.088378906, 0.122802734, 0.064553395, -0.11550903, 0.08093262, 0.03932408, -0.09718541, -0.0019182478, 0.15673392, -0.16403635, 0.013811384, 0.032226562, -0.0042550224, -0.09760393, -0.060895648, -0.038399834, 0.17564175, -0.10496358, -0.043657575, -0.00860405, -0.008204869, 0.08755929, 0.089904785, 0.112601146, 0.035609655, 0.08775111, 0.035505023, 0.0077950615, 0.07598005, -0.0043160575, 0.0001046317, 0.08889335, -0.09840611, 0.1330392, 0.02585275, -0.012989589, 0.015311105, 0.0818634, -0.21020508, -0.021833148, 0.0019356863, -0.05507115, -0.026803153, 0.009756906, -0.11226981, -0.0775844, -0.001273019, 0.1711077, 0.078700475, 0.22938755, 0.071672715, -0.07497733, -0.0074637276, 0.018711636, -0.14213344, 0.098650254, -0.0018484934, 0.11418806, 0.040121894, 0.19280134, -0.018345425, -0.11544364, -0.012520926, -0.09193639, 0.065952845, -0.17972238, -0.015851703, 0.057564873, -0.118722096, 0.054373603, 0.026088169, 0.004237584, -0.07852609, 0.017813547, 0.08367048, 0.028703962, -0.13054548, 0.071010046, 0.052350726, 0.018175397, -0.025913784, -0.07500131, 0.05092076, 0.03616769, 0.09633092, 0.011631557, 0.005318778, -0.13924845, 0.15143694, -0.059169225, -0.025251117, -0.08944266, -0.035696846, 0.063319616, -0.025229318], [-0.014340355, -0.0065743583, 0.08478219, -0.012731643, -0.063610986, -0.02306257, 0.054098945, -0.033514112, 0.08678037, 0.029407319, 0.00860305, -0.07555117, 0.013990857, 0.02740769, -0.074765615, 0.0119280135, 0.035929363, 0.013660249, -0.06078811, 0.02641369, 0.00978161, -0.010143462, -0.00011625744, -0.09909203, 0.015613374, -0.025129046, -0.10602824, 0.040355865, 0.012256441, -0.066476, -0.0015883673, -0.04874093, -0.10626511, -0.034371514, -0.017004104, -0.020147415, 0.03352992, -0.06985328, -0.010352725, 0.027919224, 0.053471155, -0.018506369, 0.09255255, -0.011550177, 0.022248767, -0.110396974, -0.027226767, -0.01567223, -0.06836373, 0.0415911, -0.057870775, 0.033342633, 0.0041514807, 0.017566498, -0.017583938, -0.05143883, -0.019438244, -0.046930224, 0.04242234, -0.060872395, -0.09153239, 0.01885505, -0.07603236, -0.11100696, -0.047188897, -0.052751813, -0.040166944, 0.1410537, -0.043311708, -0.010026296, 0.0811308, -0.0025503975, 0.07239351, 0.066705614, -0.116882324, -0.019435337, 0.036487397, 0.010044643, 0.0731579, 0.030078705, 0.09055474, -0.048890613, -0.009341286, 0.007574172, -0.050407775, -0.062023345, -0.08018857, 0.055078052, 0.014767601, -0.025617328, 0.09652274, 0.02249436, 0.017419724, -0.08472987, -0.006503151, 0.0190793, 0.060985748, -0.008765811, -0.009206863, -0.031305224, 0.042294458, -0.05695452, 0.015725998, 0.07759894, 0.022551764, -0.08478655, -0.03142511, -0.095368885, -0.013722737, -0.018484933, -0.030628022, 0.010740735, -0.0020352318, -0.034711566, -0.08020165, 0.00035022554, 0.113914855, 0.019202823, 0.12736003, 0.08703032, -0.112795874, 0.08304269, -0.12471517, 0.06556193, -0.034656342, -0.0072700866, -0.0041910806, -0.048444476, 0.06708926, 0.07506307, 0.029854184, -0.1419794, -0.049607776, -0.03223819, -0.020807901, -0.11676316, 0.0075240363, -0.1027832, 0.02008638, 0.09161522, 0.009051369, -0.015248979, 0.075329326, -0.007142101, 0.03036063, 0.061163038, -0.040643603, -0.11196409, -0.13150896, -0.019016812, 0.10153961, 0.055428643, 0.0049235024, -0.009287517, -0.05416725, -0.07630557, -0.049560547, 0.008466448, 0.021639869, 0.0064624604, -0.035853796, 0.044671923, -0.007838658, 0.015654065, -0.007350377, -0.01764243, -0.021109445, 0.00080217636, 0.084530786, -0.04042271, -0.12650554, -0.06206258, -0.0027916317, -0.10511998, -0.031311035, -0.011978876, 0.06734794, -0.01916286, -0.07609049, 0.0131501695, -0.029218402, -0.01673526, 0.019369943, -0.07788667, 0.0021485828, -0.13463266, -0.014168149, 0.043604534, 0.09214856, 0.083078295, 0.028666178, -0.00407773, 0.030912854, 0.03885614, -0.08910552, 0.013381232, -0.054787774, -0.013517834, -0.009844099, -0.08850679, 0.07209124, 0.02566383, 0.008376349, -0.036551338, -0.0866583, -0.02349563, -0.0035167877, -0.0100824265, 0.12804885, -0.056434266, -0.010531471, -0.01922898, -0.0368725, 0.08076986, -0.062113445, 0.05715216, 0.07552955, -0.006417411, -0.12475295, -0.0259156, 0.0023367745, 0.003893171, -0.018119449, -0.05556379, 0.04141635, -0.041695733, 0.02347383, 0.11498878, 0.041694276, -0.004830497, 0.08032881, -0.0015491304, 0.004896618, 0.045583088, 0.087774366, -0.04341198, 0.08200073, -0.07484363, 0.054640997, -0.029693604, 3.8510276e-05, 0.02477446, 0.027323404, -0.04504685, -0.0020555768, 0.016059512, -0.0013776507, -0.009672619, -0.019720169, -0.06673177, 0.0059087845, 0.043991815, -0.004894438, 0.017069498, 0.062263854, -0.09387207, 0.04963121, 0.014418466, -0.03264073, -0.015382312, -0.016895112, -0.044172015, -0.07238479, 0.0394229, 0.094828285, 0.09782191, -0.023963565, 0.030877976, -0.036013648, -0.018681118, 0.0954212, 0.083740234, 0.07651774, 0.08114479, 0.013685681, -0.01774234, -0.049955823, -0.11336263, -0.012162708, -0.036010742, 0.094393775, -0.03208415, -0.0023571197, 0.10270764, 0.049585253, 0.05600121, -0.08180746, -0.017713275, 0.095464796, 0.06813994, -0.11225237, -0.04899815, -0.10335287, 0.01776995, 0.05250186, 0.04949806, -0.06773812, 0.011724563, 0.011369251, -0.015718006]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame()\n",
    "final_df = []\n",
    "missed = []\n",
    "l = []\n",
    "for index, row in df.iterrows():\n",
    "    string1 = row['text']\n",
    "    #l.append(string1)\n",
    "    try:\n",
    "        result = document_vector(model, string1)\n",
    "        #print(result)\n",
    "        l.append(list(result))\n",
    "        #print(l)\n",
    "        #final_df.append(l)\n",
    "        #a_series = pd.Series(l)\n",
    "        #print(l)\n",
    "\n",
    "        #new_df = new_df.append(a_series,ignore_index=True)\n",
    "    except Exception as e:\n",
    "        list1 = [\n",
    "            0.69671315,\n",
    "            0.049782764,\n",
    "            -0.24523668,\n",
    "            -0.15872465,\n",
    "            -0.0665417,\n",
    "            0.20241983,\n",
    "            0.077576466,\n",
    "            1.9189811,\n",
    "            -0.006817713,\n",
    "            0.06951927,\n",
    "            -0.4152605,\n",
    "            -0.89838743,\n",
    "            -3.7327635,\n",
    "            -0.049629666,\n",
    "            -0.7617386,\n",
    "            -0.5561758,\n",
    "            -0.9451503,\n",
    "            0.035365578,\n",
    "            -1.0393411,\n",
    "            0.2922259,\n",
    "            -0.16664228,\n",
    "            -0.46666014,\n",
    "            0.35039356,\n",
    "            0.40681368,\n",
    "            0.38142973,\n",
    "            ]\n",
    "        l.append(create_list(300))\n",
    "        #missed.append(str(index) + ' ')\n",
    "        #print(e)\n",
    "        #final_df.append(l)\n",
    "        #a_series = pd.Series(l)\n",
    "        #new_df.append(a_series,ignore_index=True)\n",
    "print(l[:3])\n",
    "len(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "7608    1\n",
      "7609    1\n",
      "7610    1\n",
      "7611    1\n",
      "7612    1\n",
      "Name: target, Length: 7613, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create the pandas DataFrame \n",
    "label_df = df['target']\n",
    "result_df = pd.DataFrame(l, columns = create_number(301))\n",
    "#print(result_df)\n",
    "print(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1         2         3         4         5         6         7  \\\n",
      "0     0.021657  0.078870  0.076080  0.082520 -0.118947  0.011986 -0.007594   \n",
      "1     0.077427  0.018101  0.116699  0.069196  0.036717 -0.041347 -0.107396   \n",
      "2    -0.014340 -0.006574  0.084782 -0.012732 -0.063611 -0.023063  0.054099   \n",
      "3     0.177699 -0.047241  0.004203  0.100237  0.032628 -0.004854 -0.087019   \n",
      "4     0.086696  0.004797 -0.040091  0.059727 -0.036028 -0.023974 -0.019771   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "7608 -0.044428 -0.030121 -0.004439  0.026434  0.019830 -0.139926  0.021290   \n",
      "7609  0.053911  0.081741  0.038830  0.034012 -0.044636 -0.060463 -0.003998   \n",
      "7610 -0.170639 -0.028827  0.004154  0.250061  0.020477 -0.069992 -0.123230   \n",
      "7611  0.041909  0.047636  0.053714 -0.044213 -0.061146  0.001296  0.023490   \n",
      "7612  0.012226 -0.009672 -0.006827 -0.012755  0.018559  0.037983  0.033324   \n",
      "\n",
      "             8         9        10  ...       291       292       293  \\\n",
      "0    -0.057470  0.057719  0.162974  ... -0.053233  0.029869 -0.097677   \n",
      "1    -0.026311 -0.022112 -0.023856  ...  0.011632  0.005319 -0.139248   \n",
      "2    -0.033514  0.086780  0.029407  ... -0.112252 -0.048998 -0.103353   \n",
      "3    -0.037641 -0.013938 -0.041678  ...  0.113613 -0.097866 -0.112130   \n",
      "4    -0.103149 -0.033643  0.091697  ... -0.007926 -0.081602 -0.078688   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "7608 -0.063937  0.133634  0.035972  ... -0.077381  0.015780 -0.085127   \n",
      "7609 -0.056836  0.050583  0.068395  ... -0.027619 -0.010187 -0.048527   \n",
      "7610 -0.113190 -0.014473  0.001022  ...  0.097565  0.090401 -0.133423   \n",
      "7611 -0.106899  0.031756  0.046156  ...  0.013393 -0.032360 -0.066005   \n",
      "7612  0.027944  0.062068  0.102943  ...  0.096168 -0.080872 -0.111140   \n",
      "\n",
      "           294       295       296       297       298       299       300  \n",
      "0    -0.064779 -0.019053 -0.084010 -0.077952 -0.070905  0.001058  0.085795  \n",
      "1     0.151437 -0.059169 -0.025251 -0.089443 -0.035697  0.063320 -0.025229  \n",
      "2     0.017770  0.052502  0.049498 -0.067738  0.011725  0.011369 -0.015718  \n",
      "3     0.035366  0.191023  0.057757 -0.177176  0.074951  0.003723 -0.002886  \n",
      "4     0.032741 -0.001305 -0.013593  0.074550 -0.037988  0.007891  0.021899  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "7608 -0.062844  0.028121 -0.058128  0.031583 -0.080422 -0.024938 -0.070945  \n",
      "7609  0.040512  0.009972 -0.055386 -0.027669  0.023727  0.053181 -0.004862  \n",
      "7610 -0.034088  0.096466 -0.108032 -0.091553  0.026245  0.004948  0.038177  \n",
      "7611  0.030371 -0.038423 -0.023776  0.006865 -0.020031 -0.009076 -0.031666  \n",
      "7612  0.058035  0.103722 -0.146400 -0.074316  0.000329  0.026358 -0.021269  \n",
      "\n",
      "[7613 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df,label_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7907180385288967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,VotingClassifier\n",
    "mymodel = RidgeClassifier()\n",
    "lgr = LogisticRegression()\n",
    "mnb = MultinomialNB()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "mymodel.fit(X_train, y_train)\n",
    "y_pred = mymodel.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiranbal/anaconda3/envs/mlvenv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/kiranbal/anaconda3/envs/mlvenv/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7955341506129597\n"
     ]
    }
   ],
   "source": [
    "#voting\n",
    "modelnames = [('LogisticRegression',lgr),\n",
    "\t\t('SGDClassifier',sgd),\n",
    "\t\t('Gradientboosting',gbc),\n",
    "\t\t('RandomForest',rfc),\n",
    "\t\t('RidgeClassifier',mymodel)]\n",
    "\n",
    "vc = VotingClassifier(voting = 'hard',estimators=modelnames)\n",
    "vc.fit(X_train,y_train)\n",
    "y_pred = vc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_number(num):\n",
    "    mylist = []\n",
    "    for i in range(1,num):\n",
    "        mylist.append(str(i))\n",
    "    return mylist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StackingClassifier' from 'sklearn.ensemble' (/home/kiranbal/anaconda3/envs/mlvenv/lib/python3.7/site-packages/sklearn/ensemble/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-d20e23188533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#stacking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StackingClassifier' from 'sklearn.ensemble' (/home/kiranbal/anaconda3/envs/mlvenv/lib/python3.7/site-packages/sklearn/ensemble/__init__.py)"
     ]
    }
   ],
   "source": [
    "#stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "sc = StackingClassifier(estimators=modelnames)\n",
    "sc.fit(X_train,y_train)\n",
    "y_pred = sc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(n):\n",
    "    import random\n",
    "    randomlist = []\n",
    "    for i in range(0,n):\n",
    "        n = random.uniform(-2,2)\n",
    "        randomlist.append(n)\n",
    "    return randomlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "mlvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing neccessary libraries\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,#AFRICANABLAZE:  he was startled asap goaaaaal @NigeriaFC Breaking!!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze..... 12000 in America. http://t.co/\n"
     ]
    }
   ],
   "source": [
    "text = \"AFRICA,#AFRICANABLAZE:  he was startled asap goaaaaal @NigeriaFC Breaking!!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze..... 12000 in America. http://t.co/\"\n",
    "print(text)\n",
    "text2 = \"He was startled by the sudden shocking news , so  he better jumped up and down\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,#AFRICANABLAZE:  asap goaaaaal @NigeriaFC Breaking!!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze..... 12000 in America. http://t.co/\n"
     ]
    }
   ],
   "source": [
    "def removeUnicode(text):\n",
    "\t#Removes unicode strings like \"\\u002c\" and \"x96\"\n",
    "\ttext = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', text)       \n",
    "\ttext = re.sub(r'[^\\x00-\\x7f]',r'',text)\n",
    "\treturn text\n",
    "text = removeUnicode(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,#AFRICANABLAZE:  asap goaaaaal @NigeriaFC Breaking!!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze..... 12000 in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def replaceURL(text):\n",
    "\t#Replaces url address with \"url\" \n",
    "\ttext = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','<url>',text)\n",
    "\treturn text\n",
    "text=replaceURL(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,#AFRICANABLAZE:  asap goaaaaal <user> Breaking!!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze..... 12000 in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def replaceAtUser(text):\n",
    "\t#Replaces \"@user\" with \"atUser\"\n",
    "\ttext = re.sub('@[^\\s]+','<user>',text)\n",
    "\treturn text\n",
    "text = replaceAtUser(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,AFRICANABLAZE:  asap goaaaaal <user> Breaking!!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze..... 12000 in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def removeHashtag(text):\n",
    "\t#Removes hastag in front of a word\n",
    "\ttext = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "\treturn text\n",
    "text = removeHashtag(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,AFRICANABLAZE:  asap goaaaaal <user> Breaking!!!! news:Nigeria oooooooh :-D aren't flag???? wont set ablaze.....  in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def removeNumbers(text):\n",
    "\t#Removes integers\n",
    "\ttext = ''.join([i for i in text if not i.isdigit()])         \n",
    "\treturn text\n",
    "text = removeNumbers(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,AFRICANABLAZE  asap goaaaaal <user> Breaking!!!! newsNigeria oooooooh  aren't flag???? wont set ablaze.....  in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def removeEmoticons(text):\n",
    "\t#Removes emoticons from text \n",
    "\ttext = re.sub(':\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-*|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\*\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:', '', text)\n",
    "\treturn text\n",
    "text = removeEmoticons(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing multiple exclamations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,AFRICANABLAZE  asap goaaaaal <user> Breaking! newsNigeria oooooooh  aren't flag???? wont set ablaze.....  in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def replaceMulExcl(text):\n",
    "\t#Replaces repetitions of exlamation marks\n",
    "\ttext = re.sub(r\"(\\!)\\1+\", '!', text)\n",
    "\treturn text\n",
    "text = replaceMulExcl(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing multiple question marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,AFRICANABLAZE  asap goaaaaal <user> Breaking! newsNigeria oooooooh  aren't flag? wont set ablaze.....  in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def replaceMulQues(text):\n",
    "\t#Replaces repetitions of question marks\n",
    "\ttext = re.sub(r\"(\\?)\\1+\", '?', text)\n",
    "\treturn text\n",
    "text = replaceMulQues(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing multiple full stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,AFRICANABLAZE  asap goaaaaal <user> Breaking! newsNigeria oooooooh  aren't flag? wont set ablaze.  in America. <url>\n"
     ]
    }
   ],
   "source": [
    "def replaceMulStop(text):\n",
    "\t#Replaces repetitions of stop marks\n",
    "\ttext = re.sub(r\"(\\.)\\1+\", '.', text)\n",
    "\treturn text\n",
    "text = replaceMulStop(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replaces contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA,AFRICANABLAZE  asap goaaaaal <user> Breaking! newsNigeria oooooooh  are not flag? will not set ablaze.  in America. <url>\n"
     ]
    }
   ],
   "source": [
    "#Replaces contractions from a string to their equivalents\n",
    "contraction_patterns = [ (r'I\\'m', 'I am'),(r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "\t\t\t\t\t\t (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not') ]\n",
    "def replaceContraction(text):\n",
    "\tpatterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "\tfor (pattern, repl) in patterns:\n",
    "\t\t(text, count) = re.subn(pattern, repl, text)\n",
    "\treturn text\n",
    "text = replaceContraction(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA AFRICANABLAZE  asap goaaaaal <user> Breaking! newsNigeria oooooooh  are not flag? will not set ablaze   in America  <url>\n"
     ]
    }
   ],
   "source": [
    "#punctuation list for replacing\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '|', ';', \"'\", '$', '&', '/', '[', ']', '%', '=', '*', '+', '\\\\', '•',  '~', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def removePuncts(x):\n",
    "\tx = str(x)\n",
    "\tfor punct in puncts:\n",
    "\t\tif punct in x:\n",
    "\t\t\tx = x.replace(punct, f' ')\n",
    "\treturn x\n",
    "\n",
    "text = removePuncts(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting elongated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFRICA AFRICANABLAZE asap goal <user> Breaking! newsNigeria ooh are not flag? will not set ablaze in America <url>\n"
     ]
    }
   ],
   "source": [
    "#print(\"\\nshortening elongated words\\n\")\n",
    "def replaceElongated(word):\n",
    "\t#Replaces an elongated word with its basic form\n",
    "\n",
    "\trepeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "\trepl = r'\\1\\2\\3'\n",
    "\tif wordnet.synsets(word):\n",
    "\t\treturn word\n",
    "\trepl_word = repeat_regexp.sub(repl, word)\n",
    "\tif repl_word != word:      \n",
    "\t\treturn replaceElongated(repl_word)\n",
    "\telse:       \n",
    "\t\treturn repl_word\n",
    "    \n",
    "    \n",
    "#totalElongated = 0\n",
    "#totalElongated += countElongated(text)\n",
    "#print(totalElongated)\n",
    "\n",
    "regex1 = re.compile(r\"(.)\\1{2}\")\n",
    "l=[]\n",
    "for word in text.split():\n",
    "\tif(regex1.search(word)):\n",
    "\t\tnew_word = replaceElongated(word)\n",
    "\t\t##print(new_word)\n",
    "\t\tl.append(new_word)\n",
    "\telse:\n",
    "\t\tl.append(word)\n",
    "text = ' '.join(l)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'be', 'startle', 'by', 'the', 'sudden', 'shock', 'news', ',', 'so', 'he', 'well', 'jumped', 'up', 'and', 'down']\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_sentence(text2):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_tweets = ''\n",
    "    ls = ''\n",
    "    lw = []\n",
    "    for w in nltk.word_tokenize(text2):\n",
    "        #lw = lemmatizer.lemmatize(w,get_wordnet_pos(w))\n",
    "        lw.append(lemmatizer.lemmatize(w,get_wordnet_pos(w)))\n",
    "        #ls = ls + ' ' + lw\n",
    "   \n",
    "    return lw\n",
    "print(lemmatize_sentence(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "mlvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
